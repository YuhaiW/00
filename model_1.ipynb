{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKGIaeBXak6YfB1fiWP7Ns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuhaiW/00/blob/main/model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58HwpZiCqaRP"
      },
      "outputs": [],
      "source": [
        "## Putting it all together \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# check pytorch  Version \n",
        "torch.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DuADkuDjq8HC",
        "outputId": "c1464d6d-9c32-4c95-a7e9-6e0b4f106606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device:{device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9EBzZO8rLdu",
        "outputId": "a6cef51a-472c-46ce-e72c-fe04bb6912fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data preparetion "
      ],
      "metadata": {
        "id": "tXuBgtEYtF8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create some data\n",
        "\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# create range values \n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-LMuZiptiEw",
        "outputId": "5fbb250c-dda6-4176-91c5-8a8ad54e80ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]), tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## split data \n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS1H2sl9v0Ls",
        "outputId": "c05f5e5a-b599-4d1e-bd9c-3fbbff4dd7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building pytorch linear model"
      ],
      "metadata": {
        "id": "nwtD47J5wERU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a linear model by subclassing nn.modeule \n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #use nn.Linear() for creating the mpodel parameters\n",
        "    self.linear_layer = nn.Linear(in_features=1,\n",
        "                                  out_features=1)\n",
        "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "\n",
        "# set seed\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gJsPmGKzS6z",
        "outputId": "1c3d477a-de14-4610-d40f-b6440fa52d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LinearRegressionModelV2(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## check the model device\n",
        "\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnhSaLQzKLme",
        "outputId": "2e32b365-ca5c-4fff-b342-63e79425ba23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model to use the target device\n",
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Txr9ep1MUZV",
        "outputId": "983e5f0e-0ea3-4528-f485-0ac9aa633587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training\n",
        "- loss function \n",
        "- optimizer\n",
        "- training loop\n",
        "- testing loop"
      ],
      "metadata": {
        "id": "3-tu2lGnMcns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Setup loss function \n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "## setup out optimizer\n",
        "optimizer1 = torch.optim.SGD(params = model_1.parameters(), \n",
        "                             lr = 0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iZ0PVDiJN6qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## taining loop\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "## put data in the same device \n",
        "X_train  = X_train.to(device)\n",
        "y_train  = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "  y_pred = model_1(X_train)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  optimizer1.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer1.step()\n",
        "\n",
        "  ## testing \n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(X_test)\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  #print out what's happening \n",
        "\n",
        "  if epoch % 20 ==0:\n",
        "    print(f\"epoch: {epoch} | loss: {loss} | test_loss {test_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjdQ3Om8PX10",
        "outputId": "ca5bbc69-b9cb-4030-eb5d-84669c8dac8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 | loss: 0.5551779866218567 | test_loss 0.5739762187004089\n",
            "epoch: 20 | loss: 0.3247582018375397 | test_loss 0.30455657839775085\n",
            "epoch: 40 | loss: 0.09433845430612564 | test_loss 0.03513690456748009\n",
            "epoch: 60 | loss: 0.019956795498728752 | test_loss 0.045803118497133255\n",
            "epoch: 80 | loss: 0.013089174404740334 | test_loss 0.02994490973651409\n",
            "epoch: 100 | loss: 0.006215683650225401 | test_loss 0.014086711220443249\n",
            "epoch: 120 | loss: 0.0012645035749301314 | test_loss 0.013801801018416882\n",
            "epoch: 140 | loss: 0.0012645035749301314 | test_loss 0.013801801018416882\n",
            "epoch: 160 | loss: 0.0012645035749301314 | test_loss 0.013801801018416882\n",
            "epoch: 180 | loss: 0.0012645035749301314 | test_loss 0.013801801018416882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cndinv-wR4Py",
        "outputId": "52dd00ce-717b-4f83-fdbf-73ffffdd1594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.6968]], device='cuda:0')),\n",
              "             ('linear_layer.bias', tensor([0.3025], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## making and evaluating predictions \n",
        "# turn mdoel into evaluation mode \n",
        "model_1.eval()\n",
        "\n",
        "# make predictions on the test data \n",
        "with torch.inference_mode():\n",
        "  y_preds = model_1(X_test)\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcSi5ASLbBDf",
        "outputId": "34cc62a1-c500-4619-8365-202c2dd349a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8739],\n",
              "        [0.8878],\n",
              "        [0.9018],\n",
              "        [0.9157],\n",
              "        [0.9296],\n",
              "        [0.9436],\n",
              "        [0.9575],\n",
              "        [0.9714],\n",
              "        [0.9854]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## saving and loading a trained model \n"
      ],
      "metadata": {
        "id": "RGG5x7gmfdG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "## 1. create dictionary\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "## 2. Create model save path\n",
        "\n",
        "MODEL_NAME = \"01_model.pt\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "\n",
        "## 3.  Save the model state dict \n",
        "print(f\"saving model to :{MODEL_SAVE_PATH}\")\n",
        "torch.save(obj = model_1.state_dict(),\n",
        "           f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXsZtVt2futC",
        "outputId": "32d9ae42-017a-48ec-a087-125740c4f203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving model to :models/01_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O95O6fWfgqtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}